
@article{ranstam_why_2012,
	title = {Why the {P}-value culture is bad and confidence intervals a better alternative},
	volume = {20},
	abstract = {In spite of frequent discussions of misuse and misunderstanding of probability values (P-values) they still
appear in most scientific publications, and the disadvantages of erroneous and simplistic P-value
interpretations grow with the number of scientific publications. Osteoarthritis and Cartilage prefer
confidence intervals. This is a brief discussion of problems surrounding P-values and confidence intervals},
	journal = {Osteoarthritis and Cartilage},
	author = {Ranstam, J.},
	year = {2012},
	pages = {805--808},
}

@article{stanton_galton_2001,
	title = {Galton, {Pearson}, and the {Peas}: {A} {Brief} {History} of {Linear} {Regression} for {Statistics} {Instructors}},
	volume = {9},
	abstract = {An examination of publications of Sir Francis Galton and Karl Pearson revealed that Galton's work on
inherited characteristics of sweet peas led to the initial conceptualization of linear regression. Subsequent
efforts by Galton and Pearson brought about the more general techniques of multiple regression and the
product-moment correlation coefficient. Modern textbooks typically present and explain correlation prior to
introducing prediction problems and the application of linear regression. This paper presents a brief history
of how Galton originally derived and applied linear regression to problems of heredity. This history
illustrates additional approaches instructors can use to introduce simple linear regression to students.},
	number = {3},
	journal = {Journal of Statistics Education},
	author = {Stanton, Jeffrey M.},
	year = {2001},
	pages = {13},
}

@book{morris_famine_2023,
	series = {Elements in {Ancient} {Egypt} in {Context}},
	title = {Famine and {Feast} in {Ancient} {Egypt}},
	isbn = {978-1-00-907458-2},
	abstract = {This Element is about the creation and curation of social
memory in pharaonic and Greco-Roman Egypt. Ancient, Classical,
Medieval, and Ottoman sources attest to the horror that characterized
catastrophic famines. Occurring infrequently and rarely reaching the
canonical seven-years’ length, famines appeared and disappeared like
nightmares. Communities that remain aware of potentially recurring
tragedies are often advantaged in their efforts to avert or ameliorate
worst-case scenarios. For this and other reasons, pharaonic and
Greco-Roman Egyptians preserved intergenerational memories of
hunger and suffering. This Element begins with a consideration of the
trajectories typical of severe Nilotic famines and the concept of social
memory. It then argues that personal reflection and literature,
prophecy, and an annual festival of remembrance functioned – at
different times, and with varying degrees of success – to convince the
well-fed that famines had the power to unseat established order and to render a comfortably familiar world unrecognizable.},
	language = {English},
	publisher = {Cambridge University Press},
	author = {Morris, Ellen},
	month = jun,
	year = {2023},
}

@book{jaynes_probability_2003,
	title = {Probability {Theory}},
	isbn = {978-0-511-06589-7},
	language = {English},
	publisher = {Cambridge University Press},
	author = {Jaynes, E.T.},
	year = {2003},
}

@article{fienberg_when_2006,
	title = {When {Did} {Bayesian} {Inference} {Become} "{Bayesian}"},
	volume = {1},
	number = {1},
	journal = {Bayesian Analysis},
	author = {Fienberg, Stephen E.},
	year = {2006},
	pages = {1--40},
}

@article{fendler_history_2008,
	title = {The {History} of the {Bell} {Curve}: {Sorting} and the {Idea} of {Normal}},
	volume = {58},
	abstract = {Bell-curve thinking, as a model of distribution of success and failure in society, enjoys a perennial (ahistorical, objective, and law-like) status in education. As such it provides a rationale for sorting (tracking or streaming) practices in education, which has led many educators to criticize both bell-curve thinking and associated sorting practices. In this essay, Lynn Fendler and Irfan Muzaffar argue that the existing critiques of bell-curve thinking ring true for people who believe that the purpose of schooling is to promote a more equitable redistribution of resources in society; however, these arguments do not criticize the law-like character assumed for a bell curve as a representation of social reality. To extend these critiques, Fendler and Muzaffar focus on the history of the bell curve, from a representation of binomial probability, to a bearer of real things in nature, and finally to a set of expectations about how people should behave. They ultimately argue that the acceptance of bell-curve thinking in education is part of a recursive project of governance and normalization.},
	number = {1},
	journal = {Educational Theory},
	author = {Fendler, Lynn and Muzaffar, Irfan},
	year = {2008},
	pages = {63--82},
}

@article{pederson_fiducial_1978,
	title = {Fiducial {Inference}},
	volume = {46},
	number = {2},
	journal = {International Statistical Institute},
	author = {Pederson, J.G.},
	month = aug,
	year = {1978},
	pages = {147--170},
}

@article{zabell_fisher_2022,
	title = {Fisher, {Bayes}, and {Predictive} {Inference}},
	volume = {10},
	abstract = {We review historically the position of Sir R.A. Fisher towards Bayesian inference and, particulary, the classical Bayes-Laplace paradigm.  We focus on his Fiducial Argument.},
	number = {10},
	journal = {Mathematics},
	author = {Zabell, Sandy},
	year = {2022},
}

@article{ebrahimi_maximum_2000,
	title = {The {Maximum} {Entropy} {Method} for {Lifetime} {Distributions}},
	volume = {62},
	abstract = {An approach to produce a model for the data generating distribution is the
 well-known maximum entropy method. In this approach, the partial knowledge about the data
 generating distribution is formulated in terms of a set of information constraints, usually moment
 constraints, and the inference is based on the model that maximizes Shannon's entropy under
 these constraints. In this paper we investigate several problems of hazard rate function estimation
 based on the maximum entropy principle. The potential applications include developing several
 classes of the maximum entropy distributions which can be used to model different data-generating
 distributions that satisfy certain information constraints on the hazard rate function.},
	number = {2},
	journal = {Indian Statistical Institute},
	author = {Ebrahimi, Nader},
	month = jun,
	year = {2000},
	pages = {236--243},
}

@unpublished{efron_r_1998,
	type = {Lecture},
	title = {R.{A}. {Fisher} in the 21st {Century}},
	abstract = {t. Fisher is the single most important figure in 20th century
 statistics. This talk examines his influence on modern statistical think-
 ing, trying to predict how Fisherian we can expect the 21st century to
 be. Fisher's philosophy is characterized as a series of shrewd compro-
 mises between the Bayesian and frequentist viewpoints, augmented by
 some unique characteristics that are particularly useful in applied
 problems. Several current research topics are examined with an eye
 toward Fisherian influence, or the lack of it, and what this portends for
 future statistical developments. Based on the 1996 Fisher lecture, the
 article closely follows the text of that talk.},
	language = {English},
	author = {Efron, Bradley},
	month = may,
	year = {1998},
}

@article{kendall_studies_1960,
	title = {Studies in the {History} of {Probability} and {Statistics}: {Where} {Shall} the {History} of {Statistics} {Begin}?},
	volume = {47},
	journal = {Biometrika},
	author = {Kendall, M.G.},
	year = {1960},
	pages = {447--449},
}

@article{fienberg_review_1992,
	title = {Review: {A} {Brief} {History} of {Statistics} in {Three} and {One}-{Half} {Chapters}: {A} {Review} {Essay}},
	volume = {7},
	number = {2},
	journal = {Statistical Science},
	author = {Fienberg, Stephen E.},
	month = may,
	year = {1992},
	pages = {208--225},
}

@article{broemeling_account_2011,
	title = {An {Account} of {Early} {Statistical} {Inference} in {Arab} {Cryptology}},
	volume = {65},
	abstract = {Recently discovered manuscripts reveal an early use of statistical inference in Arab cryptology in the eighth through twelfth centuries A.D. The manuscripts report that al-Kindi (801-873) used relative frequency analysis some 1100 years ago to decode messages, some 800 years before the correspondence between Pascal and Fermat. Among his many accomplishments, al-Kindi is the author of the oldest known book on cryptology. This article describes an early use of statistical methods for the cryptanalysis of encrypted messages.},
	language = {English},
	number = {4},
	journal = {Ther American Statistician},
	author = {Broemeling, Lyle D.},
	month = nov,
	year = {2011},
	pages = {255--257},
}

@article{glass_john_1964,
	title = {John {Graunt} and {His} {Natural} and {Political} {Observations}},
	volume = {19},
	language = {English},
	number = {1},
	journal = {Notes and Records of the Royal Society of London},
	author = {Glass, D.V.},
	month = jun,
	year = {1964},
	pages = {63--100},
}

@book{pask_magnificent_2013,
	address = {United State of America},
	title = {Magnificent {Principia}: {Exploring} {Isaac} {Newton}'s {Masterpiece}},
	publisher = {Prometheus Books},
	author = {Pask, Collin},
	year = {2013},
}

@book{stigler_history_1986,
	title = {The {History} of {Statistics}: {The} {Measurement} {ofUncertainty} before 1900},
	publisher = {The Belknap Press of Harvard University Press},
	author = {Stigler, Stephen M.},
	year = {1986},
}

@article{goldsmith_assessing_2016,
	title = {Assessing systematic effects of stroke on motorcontrol by using hierarchical function-on-scalar regression.},
	volume = {65},
	issn = {0035-9254 1467-9876},
	doi = {10.1111/rssc.12115},
	abstract = {This work is concerned with understanding common population-level effects of stroke on motor control while accounting for possible subject-level idiosyncratic  effects. Upper extremity motor control for each subject is assessed through  repeated planar reaching motions from a central point to eight pre-specified  targets arranged on a circle. We observe the kinematic data for hand position as  a bivariate function of time for each reach. Our goal is to estimate the  bivariate function-on-scalar regression with subject-level random functional  effects while accounting for potential correlation in residual curves; covariates  of interest are severity of motor impairment and target number. We express fixed  effects and random effects using penalized splines, and allow for residual  correlation using a Wishart prior distribution. Parameters are jointly estimated  in a Bayesian framework, and we implement a computationally efficient  approximation algorithm using variational Bayes. Simulations indicate that the  proposed method yields accurate estimation and inference, and application results  suggest that the effect of stroke on motor control has a systematic component  observed across subjects.},
	language = {eng},
	number = {2},
	journal = {Journal of the Royal Statistical Society. Series C, Applied statistics},
	author = {Goldsmith, Jeff and Kitago, Tomoko},
	month = feb,
	year = {2016},
	pmid = {27546913},
	pmcid = {PMC4988692},
	note = {Place: England},
	keywords = {Bayesian Regression, Bivariate Data, Gibbs Sampler, Penalized Splines, Variational Bayes},
	pages = {215--236},
}

@book{cheney_numerical_2013,
	address = {Boston, MA},
	edition = {7th},
	title = {Numerical {Mathematics} and {Computing}},
	publisher = {Brooks/Cole},
	author = {Cheney, Ward and Kincaid, David},
	year = {2013},
}

@article{perperoglou_review_2019,
	title = {A review of spline function procedures in {R}},
	volume = {19},
	issn = {1471-2288},
	url = {https://doi.org/10.1186/s12874-019-0666-3},
	doi = {10.1186/s12874-019-0666-3},
	abstract = {With progress on both the theoretical and the computational fronts the use of spline modelling has become an established tool in statistical regression analysis. An important issue in spline modelling is the availability of user friendly, well documented software packages. Following the idea of the STRengthening Analytical Thinking for Observational Studies initiative to provide users with guidance documents on the application of statistical methods in observational research, the aim of this article is to provide an overview of the most widely used spline-based techniques and their implementation in R.},
	number = {1},
	journal = {BMC Medical Research Methodology},
	author = {Perperoglou, Aris and Sauerbrei, Willi and Abrahamowicz, Michal and Schmid, Matthias},
	month = mar,
	year = {2019},
	pages = {46},
}

@book{gelman_bayesian_2013,
	series = {Chapman \& {Hall}/{CRC} {Texts} in {Statistical} {Science}},
	title = {Bayesian {Data} {Analysis}, {Third} {Edition}},
	isbn = {978-1-4398-4095-5},
	url = {https://books.google.com/books?id=ZXL6AQAAQBAJ},
	publisher = {Taylor \& Francis},
	author = {Gelman, A. and Carlin, J.B. and Stern, H.S. and Dunson, D.B. and Vehtari, A. and Rubin, D.B.},
	year = {2013},
	lccn = {2013039507},
}

@inproceedings{casciola_spline_1996,
	title = {Spline {Curves} in {Polar} and {Cartesian} {Coordinates}},
	url = {https://api.semanticscholar.org/CorpusID:18269611},
	author = {Casciola, Giulio and Morigi, Serena and E, A. Le M. Ehaut and Rabut, Christophe and Schumaker, Larry L.},
	year = {1996},
}

@article{brumback_smoothing_1998,
	title = {Smoothing {Spline} {Models} for the {Analysis} of {Nested} and {Crossed} {Samples} of {Curves}},
	volume = {93},
	issn = {01621459, 1537274X},
	url = {http://www.jstor.org/stable/2669837},
	doi = {10.2307/2669837},
	abstract = {[We introduce a class of models for an additive decomposition of groups of curves stratified by crossed and nested factors, generalizing smoothing splines to such samples by associating them with a corresponding mixed-effects model. The models are also useful for imputation of missing data and exploratory analysis of variance. We prove that the best linear unbiased predictors (BLUPs) from the extended mixed-effects model correspond to solutions of a generalized penalized regression where smoothing parameters are directly related to variance components, and we show that these solutions are natural cubic splines. The model parameters are estimated using a highly efficient implementation of the EM algorithm for restricted maximum likelihood (REML) estimation based on a preliminary eigenvector decomposition. Variability of computed estimates can be assessed with asymptotic techniques or with a novel hierarchical bootstrap resampling scheme for nested mixed-effects models. Our methods are applied to menstrual cycle data from studies of reproductive function that measure daily urinary progesterone; the sample of progesterone curves is stratified by cycles nested within subjects nested within conceptive and nonconceptive groups.]},
	number = {443},
	urldate = {2024-10-22},
	journal = {Journal of the American Statistical Association},
	author = {Brumback, Babette A. and Rice, John A.},
	year = {1998},
	note = {Publisher: [American Statistical Association, Taylor \& Francis, Ltd.]},
	pages = {961--976},
}

@article{paul_h_c_eilers_flexible_1996,
	title = {Flexible smoothing with {B}-splines and penalties},
	volume = {11},
	url = {https://doi.org/10.1214/ss/1038425655},
	doi = {10.1214/ss/1038425655},
	number = {2},
	journal = {Statistical Science},
	author = {{Paul H. C. Eilers} and {Brian D. Marx}},
	month = may,
	year = {1996},
	pages = {89--121},
}

@article{betancourt_conceptual_2017,
	title = {A conceptual introduction to {Hamiltonian} {Monte} {Carlo}},
	journal = {arXiv preprint arXiv:1701.02434},
	author = {Betancourt, Michael},
	year = {2017},
}

@article{rice_estimating_1991,
	title = {Estimating the {Mean} and {Covariance} {Structure} {Nonparametrically} {When} the {Data} are {Curves}},
	volume = {53},
	issn = {0035-9246},
	url = {https://doi.org/10.1111/j.2517-6161.1991.tb01821.x},
	doi = {10.1111/j.2517-6161.1991.tb01821.x},
	abstract = {We develop methods for the analysis of a collection of curves which are stochastically modelled as independent realizations of a random function with an unknown mean and covariance structure. We propose a method of estimating the mean function non-parametrically under the assumption that it is smooth. We suggest a variant on the usual form of cross-validation for choosing the degree of smoothing to be employed. This method of cross-validation, which consists of deleting entire sample curves, has the advantage that it does not require that the covariance structure be known or estimated. In the estimation of the covariance structure, we are primarily concerned with models in which the first few eigenfunctions are smooth and the eigenvalues decay rapidly, so that the variability is predominantly of large scale. We propose smooth nonparametric estimates of the eigenfunctions and a suitable method of cross-validation to determine the amount of smoothing. Our methods are applied to data on the gaits of a group of 5-year-old children.},
	number = {1},
	urldate = {2024-10-27},
	journal = {Journal of the Royal Statistical Society: Series B (Methodological)},
	author = {Rice, John A. and Silverman, B. W.},
	month = sep,
	year = {1991},
	pages = {233--243},
}

@article{ramsay_when_1982,
	title = {When the data are functions},
	volume = {47},
	issn = {1860-0980},
	url = {https://doi.org/10.1007/BF02293704},
	doi = {10.1007/BF02293704},
	abstract = {A datum is often a continuous functionx(t) of a variable such as time observed over some interval. One or more such functions are observed for each subject or unit of observation. The extension of classical data analytic techniques designed forp-variate observations to such data is discussed. The essential step is the expression of the classical problem in the language of functional analysis, after which the extension to functions is a straightforward matter. A schematic device called the duality diagram is a very useful tool for describing an analysis and for suggesting new possibilities. Least squares approximation, descriptive statistics, principal components analysis, and canonical correlation analysis are discussed within this broader framework.},
	number = {4},
	journal = {Psychometrika},
	author = {Ramsay, J. O.},
	month = dec,
	year = {1982},
	pages = {379--396},
}

@article{ulf_grenander_stochastic_1950,
	title = {Stochastic processes and statistical inference},
	volume = {1},
	url = {https://doi.org/10.1007/BF02590638},
	doi = {10.1007/BF02590638},
	number = {3},
	journal = {Arkiv för Matematik},
	author = {{Ulf Grenander}},
	month = oct,
	year = {1950},
	pages = {195--277},
}

@article{goldsmith_corrected_2013,
	title = {Corrected confidence bands for functional data using principal components.},
	volume = {69},
	copyright = {Copyright © 2013, The International Biometric Society.},
	issn = {1541-0420 0006-341X},
	doi = {10.1111/j.1541-0420.2012.01808.x},
	abstract = {Functional principal components (FPC) analysis is widely used to decompose and express functional observations. Curve estimates implicitly condition on basis  functions and other quantities derived from FPC decompositions; however these  objects are unknown in practice. In this article, we propose a method for  obtaining correct curve estimates by accounting for uncertainty in FPC  decompositions. Additionally, pointwise and simultaneous confidence intervals  that account for both model- and decomposition-based variability are constructed.  Standard mixed model representations of functional expansions are used to  construct curve estimates and variances conditional on a specific decomposition.  Iterated expectation and variance formulas combine model-based conditional  estimates across the distribution of decompositions. A bootstrap procedure is  implemented to understand the uncertainty in principal component decomposition  quantities. Our method compares favorably to competing approaches in simulation  studies that include both densely and sparsely observed functions. We apply our  method to sparse observations of CD4 cell counts and to dense white-matter tract  profiles. Code for the analyses and simulations is publicly available, and our  method is implemented in the R package refund on CRAN.},
	language = {eng},
	number = {1},
	journal = {Biometrics},
	author = {Goldsmith, J. and Greven, S. and Crainiceanu, C.},
	month = mar,
	year = {2013},
	pmid = {23003003},
	pmcid = {PMC3962763},
	note = {Place: England},
	keywords = {Humans, Computer Simulation, *Models, Statistical, *Confidence Intervals, Brain/pathology, CD4 Lymphocyte Count, HIV Infections/diagnosis, HIV/growth \& development, Magnetic Resonance Imaging, Multiple Sclerosis/pathology, Principal Component Analysis/*methods},
	pages = {41--51},
}

@article{goldsmith_generalized_2015,
	title = {Generalized multilevel function-on-scalar regression and principal component analysis.},
	volume = {71},
	copyright = {© 2015, The International Biometric Society.},
	issn = {1541-0420 0006-341X},
	doi = {10.1111/biom.12278},
	abstract = {This manuscript considers regression models for generalized, multilevel functional responses: functions are generalized in that they follow an  exponential family distribution and multilevel in that they are clustered within  groups or subjects. This data structure is increasingly common across scientific  domains and is exemplified by our motivating example, in which binary curves  indicating physical activity or inactivity are observed for nearly 600 subjects  over 5 days. We use a generalized linear model to incorporate scalar covariates  into the mean structure, and decompose subject-specific and subject-day-specific  deviations using multilevel functional principal components analysis. Thus,  functional fixed effects are estimated while accounting for within-function and  within-subject correlations, and major directions of variability within and  between subjects are identified. Fixed effect coefficient functions and principal  component basis functions are estimated using penalized splines; model parameters  are estimated in a Bayesian framework using Stan, a programming language that  implements a Hamiltonian Monte Carlo sampler. Simulations designed to mimic the  application have good estimation and inferential properties with reasonable  computation times for moderate datasets, in both cross-sectional and multilevel  scenarios; code is publicly available. In the application we identify effects of  age and BMI on the time-specific change in probability of being active over a  24-hour period; in addition, the principal components analysis identifies the  patterns of activity that distinguish subjects and days within subjects.},
	language = {eng},
	number = {2},
	journal = {Biometrics},
	author = {Goldsmith, Jeff and Zipunnikov, Vadim and Schrack, Jennifer},
	month = jun,
	year = {2015},
	pmid = {25620473},
	pmcid = {PMC4479975},
	note = {Place: England},
	keywords = {Aged, Aged, 80 and over, Female, Humans, Male, Middle Aged, Computer Simulation, Models, Statistical, Linear Models, Biometry, *Regression Analysis, *Principal Component Analysis, Accelerometry, Accelerometry/statistics \& numerical data, Aging/physiology, Bayes Theorem, Bayesian inference, Generalized functional data, Hamiltonian Monte Carlo, Monte Carlo Method, Motor Activity, Penalized splines},
	pages = {344--353},
}

@article{guo_functional_2002,
	title = {Functional {Mixed} {Effects} {Models}},
	volume = {58},
	issn = {0006-341X},
	url = {https://doi.org/10.1111/j.0006-341X.2002.00121.x},
	doi = {10.1111/j.0006-341X.2002.00121.x},
	abstract = {Summary. In this article, a new class of functional models in which smoothing splines are used to model fixed effects as well as random effects is introduced. The linear mixed effects models are extended to non-parametric mixed effects models by introducing functional random effects, which are modeled as realizations of zero-mean stochastic processes. The fixed functional effects and the random functional effects are modeled in the same functional space, which guarantee the population-average and subject-specific curves have the same smoothness property. These models inherit the flexibility of the linear mixed effects models in handling complex designs and correlation structures, can include continuous covariates as well as dummy factors in both the fixed or random design matrices, and include the nested curves models as special cases. Two estimation procedures are proposed. The first estimation procedure exploits the connection between linear mixed effects models and smoothing splines and can be fitted using existing software. The second procedure is a sequential estimation procedure using Kalman filtering. This algorithm avoids inversion of large dimensional matrices and therefore can be applied to large data sets. A generalized maximum likelihood (GML) ratio test is proposed for inference and model selection. An application to comparison of cortisol profiles is used as an illustration.},
	number = {1},
	urldate = {2024-10-28},
	journal = {Biometrics},
	author = {Guo, Wensheng},
	month = mar,
	year = {2002},
	note = {Publisher: John Wiley \& Sons, Ltd},
	keywords = {Functional models, Kalman filter, Mixed effects models, Sequential estimation, Smoothing spline, State space models},
	pages = {121--128},
}

@book{ramsay_functional_2005,
	series = {Springer {Series} in {Statistics}},
	title = {Functional {Data} {Analysis}},
	isbn = {978-0-387-40080-8},
	url = {https://books.google.com/books?id=mU3dop5wY_4C},
	publisher = {Springer},
	author = {Ramsay, J. and Silverman, B.W.},
	year = {2005},
	lccn = {2005923773},
}

@article{plackett_studies_1972,
	title = {Studies in the {History} of {Probability} and {Statistics}. {XXIX}: {The} {Discovery} of the {Method} of {Least} {Squares}},
	volume = {59},
	issn = {00063444, 14643510},
	url = {http://www.jstor.org/stable/2334569},
	doi = {10.2307/2334569},
	abstract = {[The circumstances in which the discovery of the method of least squares took place and the course of the ensuing controversy are examined in detail with the aid of correspondence. Some conclusions are drawn about the attitudes of the main participants and the nature of historical research in statistics.]},
	number = {2},
	urldate = {2024-10-29},
	journal = {Biometrika},
	author = {Plackett, R. L.},
	year = {1972},
	note = {Publisher: [Oxford University Press, Biometrika Trust]},
	pages = {239--251},
}

@article{stephen_m_stigler_gauss_1981,
	title = {Gauss and the {Invention} of {Least} {Squares}},
	volume = {9},
	url = {https://doi.org/10.1214/aos/1176345451},
	doi = {10.1214/aos/1176345451},
	number = {3},
	journal = {The Annals of Statistics},
	author = {{Stephen M. Stigler}},
	month = may,
	year = {1981},
	pages = {465--474},
}

@article{zabell_commentary_2012,
	title = {Commentary on {Alan} {M}. {Turing}: {The} {Applications} of {Probability} to {Cryptography}},
	volume = {36},
	issn = {0161-1194},
	url = {https://doi.org/10.1080/01611194.2012.697811},
	doi = {10.1080/01611194.2012.697811},
	number = {3},
	journal = {Cryptologia},
	author = {Zabell, Sandy},
	month = jul,
	year = {2012},
	note = {Publisher: Taylor \& Francis},
	pages = {191--214},
	annote = {doi: 10.1080/01611194.2012.697811},
}

@inproceedings{taylor_alan_2015,
	title = {Alan {M}. {Turing}: {The} {Applications} of {Probability} to {Cryptography}},
	url = {https://api.semanticscholar.org/CorpusID:116894950},
	author = {Taylor, Ian},
	year = {2015},
}

@article{harrison_introduction_2010,
	title = {Introduction {To} {Monte} {Carlo} {Simulation}.},
	volume = {1204},
	issn = {0094-243X},
	doi = {10.1063/1.3295638},
	abstract = {This paper reviews the history and principles of Monte Carlo simulation, emphasizing techniques commonly used in the simulation of medical imaging.},
	language = {eng},
	journal = {AIP conference proceedings},
	author = {Harrison, Robert L.},
	month = jan,
	year = {2010},
	pmid = {20733932},
	pmcid = {PMC2924739},
	note = {Place: United States},
	pages = {17--21},
}

@book{wahba_spline_1990,
	series = {{CBMS}-{NSF} {Regional} {Conference} {Series} in {Applied} {Mathematics}},
	title = {Spline {Models} for {Observational} {Data}},
	isbn = {978-0-89871-244-5},
	url = {https://books.google.com/books?id=ScRQJEETs0EC},
	publisher = {Society for Industrial and Applied Mathematics},
	author = {Wahba, G.},
	year = {1990},
	lccn = {89028687},
}

@article{dung_direct_2017,
	title = {A direct method to solve optimal knots of {B}-spline curves: {An} application for non-uniform {B}-spline curves fitting.},
	volume = {12},
	issn = {1932-6203},
	doi = {10.1371/journal.pone.0173857},
	abstract = {B-spline functions are widely used in many industrial applications such as computer graphic representations, computer aided design, computer aided  manufacturing, computer numerical control, etc. Recently, there exist some  demands, e.g. in reverse engineering (RE) area, to employ B-spline curves for  non-trivial cases that include curves with discontinuous points, cusps or turning  points from the sampled data. The most challenging task in these cases is in the  identification of the number of knots and their respective locations in  non-uniform space in the most efficient computational cost. This paper presents a  new strategy for fitting any forms of curve by B-spline functions via local  algorithm. A new two-step method for fast knot calculation is proposed. In the  first step, the data is split using a bisecting method with predetermined  allowable error to obtain coarse knots. Secondly, the knots are optimized, for  both locations and continuity levels, by employing a non-linear least squares  technique. The B-spline function is, therefore, obtained by solving the ordinary  least squares problem. The performance of the proposed method is validated by  using various numerical experimental data, with and without simulated noise,  which were generated by a B-spline function and deterministic parametric  functions. This paper also discusses the benchmarking of the proposed method to  the existing methods in literature. The proposed method is shown to be able to  reconstruct B-spline functions from sampled data within acceptable tolerance. It  is also shown that, the proposed method can be applied for fitting any types of  curves ranging from smooth ones to discontinuous ones. In addition, the method  does not require excessive computational cost, which allows it to be used in  automatic reverse engineering applications.},
	language = {eng},
	number = {3},
	journal = {PloS one},
	author = {Dung, Van Than and Tjahjowidodo, Tegoeh},
	year = {2017},
	pmid = {28319131},
	pmcid = {PMC5358887},
	note = {Place: United States},
	keywords = {Computer Simulation, *Algorithms, Computer Graphics, Statistics as Topic/*methods},
	pages = {e0173857},
}

@article{grove_ct_2010,
	title = {From {CT} to {NURBS}: {Contour} {Fitting} with {B}-spline {Curves}},
	volume = {7},
	issn = {null},
	url = {https://doi.org/10.1080/16864360.2010.10738807},
	doi = {10.1080/16864360.2010.10738807},
	number = {sup1},
	journal = {Computer-Aided Design and Applications},
	author = {Grove, Olya and Rajab, Khairan and Piegl, Les A.},
	month = jan,
	year = {2010},
	note = {Publisher: Taylor \& Francis},
	pages = {1--19},
	annote = {doi: 10.1080/16864360.2010.10738807},
}

@article{ichida_curve_1977,
	title = {Curve {Fitting} by a {One}-{Pass} {Method} {With} a {Piecewise} {Cubic} {Polynomial}},
	volume = {3},
	issn = {0098-3500},
	url = {https://doi.org/10.1145/355732.355737},
	doi = {10.1145/355732.355737},
	number = {2},
	journal = {ACM Trans. Math. Softw.},
	author = {Ichida, Kozo and Kiyono, Takeshi and Yoshimoto, Fujiichi},
	month = jun,
	year = {1977},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	pages = {164--174},
}

@article{xuming_he_data-adaptive_2001,
	title = {A data-adaptive knot selection scheme for fitting splines},
	volume = {8},
	issn = {1558-2361},
	doi = {10.1109/97.917695},
	number = {5},
	journal = {IEEE Signal Processing Letters},
	author = {{Xuming He} and {Lixin Shen} and {Zuowei Shen}},
	month = may,
	year = {2001},
	pages = {137--139},
}

@article{lyche_knot_1987,
	title = {Knot removal for parametric {B}-spline curves and surfaces},
	volume = {4},
	issn = {0167-8396},
	url = {https://www.sciencedirect.com/science/article/pii/0167839687900136},
	doi = {10.1016/0167-8396(87)90013-6},
	abstract = {This paper is the third in a sequence of papers in which a knot removal strategy for splines, based on certain discrete norms, is developed. In the first paper, approximation methods defined as best approximations in these norms were discussed, while in the second paper a knot removal strategy for spline functions was developed. In this paper the knot removal strategy is extended to parametric spline curves and tensor product surfaces. The method has been implemented and thoroughly tested on a computer. We illustrate with several examples and applications.},
	number = {3},
	journal = {Computer Aided Geometric Design},
	author = {Lyche, Tom and Mørken, Knut},
	month = nov,
	year = {1987},
	keywords = {Splines, B-splines, curves, discrete norms, knot removal, tensor product surfaces},
	pages = {217--230},
}

@article{locantore_robust_1999,
	title = {Robust principal component analysis for functional data},
	volume = {8},
	issn = {1863-8260},
	url = {https://doi.org/10.1007/BF02595862},
	doi = {10.1007/BF02595862},
	abstract = {A method for exploring the structure of populations of complex objects, such as images, is considered. The objects are summarized by feature vectors. The statistical backbone is Principal Component Analysis in the space of feature vectors. Visual insights come from representing the results in the original data space. In an ophthalmological example, endemic outliers motivate the development of a bounded influence approach to PCA.},
	number = {1},
	journal = {Test},
	author = {Locantore, N. and Marron, J. S. and Simpson, D. G. and Tripoli, N. and Zhang, J. T. and Cohen, K. L. and Boente, Graciela and Fraiman, Ricardo and Brumback, Babette and Croux, Christophe and Fan, Jianqing and Kneip, Alois and Marden, John I. and Peña, Daniel and Prieto, Javier and Ramsay, Jim O. and Valderrama, Mariano J. and Aguilera, Ana M. and Locantore, N. and Marron, J. S. and Simpson, D. G. and Tripoli, N. and Zhang, J. T. and Cohen, K. L.},
	month = jun,
	year = {1999},
	pages = {1--73},
}

@article{liggett_look_2003,
	title = {A {Look} at {Mass} {Spectral} {Measurement}},
	volume = {16},
	issn = {0933-2480},
	url = {https://doi.org/10.1080/09332480.2003.10554871},
	doi = {10.1080/09332480.2003.10554871},
	number = {4},
	journal = {CHANCE},
	author = {Liggett, Walter and Cazares, Lisa and Semmes, O. John},
	month = sep,
	year = {2003},
	note = {Publisher: ASA Website},
	pages = {24--28},
	annote = {doi: 10.1080/09332480.2003.10554871},
}

@article{kneip_inference_2001,
	title = {Inference for {Density} {Families} {Using} {Functional} {Principal} {Component} {Analysis}},
	volume = {96},
	issn = {0162-1459},
	url = {https://doi.org/10.1198/016214501753168235},
	doi = {10.1198/016214501753168235},
	number = {454},
	journal = {Journal of the American Statistical Association},
	author = {Kneip, Alois and Utikal, Klaus J},
	month = jun,
	year = {2001},
	note = {Publisher: ASA Website},
	pages = {519--542},
	annote = {doi: 10.1198/016214501753168235},
}

@article{koner_second-generation_2023,
	title = {Second-generation functional data},
	volume = {10},
	issn = {2326-8298},
	number = {1},
	journal = {Annual review of statistics and its application},
	author = {Koner, Salil and Staicu, Ana-Maria},
	year = {2023},
	note = {Publisher: Annual Reviews},
	pages = {547--572},
}

@article{morris_functional_2015,
	title = {Functional regression},
	volume = {2},
	issn = {2326-8298},
	number = {1},
	journal = {Annual Review of Statistics and Its Application},
	author = {Morris, Jeffrey S},
	year = {2015},
	note = {Publisher: Annual Reviews},
	pages = {321--359},
}

@article{murray_bayes_0000,
	title = {Bayes' rule},
	url = {https://jaredsmurray.github.io/sta371h/files/05_bayes_rule%20(2).pdf},
	author = {Murray, J. S.},
	year = {0000},
}

@article{lawrence_d_stone_search_2014,
	title = {Search for the {Wreckage} of {Air} {France} {Flight} {AF} 447},
	volume = {29},
	url = {https://doi.org/10.1214/13-STS420},
	doi = {10.1214/13-STS420},
	number = {1},
	journal = {Statistical Science},
	author = {{Lawrence D. Stone} and {Colleen M. Keller} and {Thomas M. Kratzke} and {Johan P. Strumpfer}},
	month = feb,
	year = {2014},
	pages = {69--80},
}

@article{faraway_regression_1997,
	title = {Regression {Analysis} for a {Functional} {Response}},
	volume = {39},
	issn = {0040-1706},
	url = {https://www.tandfonline.com/doi/abs/10.1080/00401706.1997.10485118},
	doi = {10.1080/00401706.1997.10485118},
	number = {3},
	journal = {Technometrics},
	author = {Faraway, Julian J.},
	month = aug,
	year = {1997},
	note = {Publisher: ASA Website},
	pages = {254--261},
	annote = {doi: 10.1080/00401706.1997.10485118},
}

@article{james_principal_2000,
	title = {Principal component models for sparse functional data},
	volume = {87},
	issn = {0006-3444},
	url = {https://doi.org/10.1093/biomet/87.3.587},
	doi = {10.1093/biomet/87.3.587},
	abstract = {The elements of a multivariate dataset are often curves rather than single points. Functional principal components can be used to describe the modes of variation of such curves. If one has complete measurements for each individual curve or, as is more common, one has measurements on a fine grid taken at the same time points for all curves, then many standard techniques may be applied. However, curves are often measured at an irregular and sparse set of time points which can differ widely across individuals. We present a technique for handling this more difficult case using a reduced rank mixed effects framework.},
	number = {3},
	urldate = {2024-11-19},
	journal = {Biometrika},
	author = {James, GM and Hastie, TJ and Sugar, CA},
	month = sep,
	year = {2000},
	pages = {587--602},
}

@article{reiss_fast_2010,
	title = {Fast function-on-scalar regression with penalized basis expansions.},
	volume = {6},
	issn = {1557-4679},
	doi = {10.2202/1557-4679.1246},
	abstract = {Regression models for functional responses and scalar predictors are often fitted by means of basis functions, with quadratic roughness penalties applied to avoid  overfitting. The fitting approach described by Ramsay and Silverman in the 1990 s  amounts to a penalized ordinary least squares (P-OLS) estimator of the  coefficient functions. We recast this estimator as a generalized ridge regression  estimator, and present a penalized generalized least squares (P-GLS) alternative.  We describe algorithms by which both estimators can be implemented, with  automatic selection of optimal smoothing parameters, in a more computationally  efficient manner than has heretofore been available. We discuss pointwise  confidence intervals for the coefficient functions, simultaneous inference by  permutation tests, and model selection, including a novel notion of pointwise  model selection. P-OLS and P-GLS are compared in a simulation study. Our methods  are illustrated with an analysis of age effects in a functional magnetic  resonance imaging data set, as well as a reanalysis of a now-classic Canadian  weather data set. An R package implementing the methods is publicly available.},
	language = {eng},
	number = {1},
	journal = {The international journal of biostatistics},
	author = {Reiss, Philip T. and Huang, Lei and Mennes, Maarten},
	year = {2010},
	pmid = {21969982},
	note = {Place: Germany},
	keywords = {Female, Humans, Male, Adult, Middle Aged, Models, Statistical, *Algorithms, *Regression Analysis, *Least-Squares Analysis, Age Factors, Canada, Data Interpretation, Statistical, Magnetic Resonance Imaging/statistics \& numerical data, Weather},
	pages = {Article 28},
}

@article{kirschenmann_concepts_1972,
	title = {Concepts of {Randomness}},
	volume = {1},
	issn = {00223611, 15730433},
	url = {http://www.jstor.org/stable/30226051},
	number = {3/4},
	urldate = {2024-11-20},
	journal = {Journal of Philosophical Logic},
	author = {Kirschenmann, Peter},
	year = {1972},
	note = {Publisher: Springer},
	pages = {395--414},
}

@article{kendall_theory_1941,
	title = {A {Theory} of {Randomness}},
	volume = {32},
	issn = {00063444, 14643510},
	url = {http://www.jstor.org/stable/2332245},
	doi = {10.2307/2332245},
	number = {1},
	urldate = {2024-11-20},
	journal = {Biometrika},
	author = {Kendall, M. G.},
	year = {1941},
	note = {Publisher: [Oxford University Press, Biometrika Trust]},
	pages = {1--15},
}
